{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac959c4b-d7a9-4949-9c39-2ab46fbf82cd",
   "metadata": {},
   "source": [
    "# Lesson 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df1e2b-2079-4dee-84e9-77e13dd31e05",
   "metadata": {},
   "source": [
    "### Getting started with Llama 2\n",
    "\n",
    "**Update: Llama 3 was released on April 18 and this notebook has been updated to show how to use both Llama 3 and Llama 2 models hosted on Together.ai.**\n",
    "\n",
    "The code to call the Llama 2 models through the Together.ai hosted API service has been wrapped into a helper function called `llama`. You can take a look at this code if you like by opening the utils.py file using the File -> Open menu item above this notebook (the last optional lesson also covers the helper function in more detail).\n",
    "\n",
    "Note: To see how to run Llama 2 or 3 locally on your own computer, you can go to the last section of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10075542-6019-40b6-b3c1-532383e4a6dd",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# import llama helper function\n",
    "from utils import llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a549fd-dd50-4ae1-a5d8-ce00fdc707a3",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# define the prompt\n",
    "prompt = \"Help me write a birthday card for my dear friend Andrew.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d46c4b-2926-44a9-9e25-befb6bd6648c",
   "metadata": {},
   "source": [
    "**Note:** LLMs can have different responses for the same prompt, which is why throughout the course, the responses you get might be slightly different than the ones in the lecture videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b89f4c48-363d-4ddb-8f20-215bbd47004a",
   "metadata": {
    "height": 89
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course, I'd be happy to help you write a birthday card for your dear friend Andrew! Here are a few suggestions:\n",
      "\n",
      "1. Personalized Message: Start by writing a personalized message that expresses your feelings towards Andrew. You could say something like:\n",
      "\n",
      "\"Happy birthday to my amazing friend Andrew! üéâ I'm so grateful for our friendship and all the adventures we've shared together. Here's to another year of making memories and creating new ones! ü•≥\"\n",
      "\n",
      "2. Funny Quote: If you want to add a bit of humor to your card, you could use a funny quote that relates to Andrew's personality or interests. For example:\n",
      "\n",
      "\"Happy birthday to my favorite person to hang out with! üòú I'm so glad we're friends because you make every day brighter and more entertaining. Here's to another year of good times and great memories! üéâ\"\n",
      "\n",
      "3. Heartfelt Message: If you want to write a more heartfelt message, you could express your appreciation for Andrew's friendship and the impact he's had on your life. Here's an example:\n",
      "\n",
      "\"Dear Andrew, happy birthday to an incredible friend! üíï I'm so grateful for the day we met and for the adventures we've shared together. You bring so much joy and love into my life, and I'm so lucky to have you by my side. Here's to another year of love, laughter, and making memories together! ü•≥\"\n",
      "\n",
      "4. Inside Joke: If you and Andrew share an inside joke or a funny story, you could include it in the card for an extra touch of personalization. For example:\n",
      "\n",
      "\"Happy birthday to my favorite person to share a slice of pizza with! üçï I'm so glad we're friends because you always make me laugh and you're the best partner in crime. Here's to another year of sneaking into the office kitchen and eating all the snacks! üòú\"\n",
      "\n",
      "Remember, the most important thing is to be sincere and genuine in your message. Write from the heart and let Andrew know how much he means to you. Happy birthday to your dear friend!\n"
     ]
    }
   ],
   "source": [
    "# pass prompt to the llama function, store output as 'response' then print\n",
    "response = llama(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a573ca3f-9ffc-4f08-91eb-7e88d99d2f9f",
   "metadata": {
    "height": 89
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "[INST]Help me write a birthday card for my dear friend Andrew.[/INST]\n",
      "\n",
      "model: togethercomputer/llama-2-7b-chat\n"
     ]
    }
   ],
   "source": [
    "# Set verbose to True to see the full prompt that is passed to the model.\n",
    "prompt = \"Help me write a birthday card for my dear friend Andrew.\"\n",
    "response = llama(prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c9bc9-9777-45bb-9e52-1cd99a42e716",
   "metadata": {},
   "source": [
    "### Chat vs. base models\n",
    "\n",
    "Ask model a simple question to demonstrate the different behavior of chat vs. base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37cc261-a9d5-486c-a0f1-7f0ce93f403e",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "[INST]What is the capital of France?[/INST]\n",
      "\n",
      "model: togethercomputer/llama-2-7b-chat\n"
     ]
    }
   ],
   "source": [
    "### chat model\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = llama(prompt, \n",
    "                 verbose=True,\n",
    "                 model=\"togethercomputer/llama-2-7b-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d596d0-9469-4220-a03a-b50b0226776d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71bef6df-ce83-4be7-98a7-cd0c353c4188",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "What is the capital of France?\n",
      "\n",
      "model: togethercomputer/llama-2-7b\n"
     ]
    }
   ],
   "source": [
    "### base model\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = llama(prompt, \n",
    "                 verbose=True,\n",
    "                 add_inst=False,\n",
    "                 model=\"togethercomputer/llama-2-7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bf01a1-2c3e-4073-a4b7-546f5de0e5a1",
   "metadata": {},
   "source": [
    "Note how the prompt **does not** include the `[INST]` and `[/INST]` tags as `add_inst` was set to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1941be3a-de66-4d08-808e-f93a0393f864",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'message': 'Unable to access non-serverless model togethercomputer/llama-2-7b. Please visit https://api.together.ai/models/togethercomputer/llama-2-7b to create and start a new dedicated endpoint for the model.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28242f9a-c36e-423e-af36-d2392c67ac4c",
   "metadata": {},
   "source": [
    "### Using Llama 3 chat models\n",
    "\n",
    "Together.ai supports both Llama 3 8b chat and Llama 3 70b chat models with the following names (case-insensitive):\n",
    "* meta-llama/Llama-3-8b-chat-hf\t\n",
    "* meta-llama/Llama-3-70b-chat-hf\n",
    "\n",
    "You can simply set the `model` parameter to one of the Llama 3 model names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e3d0776-6f1d-49dc-a8eb-302a78e71b01",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "What is the capital of France?\n",
      "\n",
      "model: META-LLAMA/LLAMA-3-8B-CHAT-HF\n"
     ]
    }
   ],
   "source": [
    "response = llama(prompt, \n",
    "                 verbose=True,\n",
    "                 model=\"META-LLAMA/LLAMA-3-8B-CHAT-HF\", \n",
    "                 add_inst=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65423187-e2dc-492a-86fa-e3431238a6d1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**\n",
      "A) Berlin\n",
      "B) Paris\n",
      "C) London\n",
      "D) Rome\n",
      "\n",
      "Answer: B) Paris\n",
      "#### 2. What is the largest planet in our solar system?\n",
      "A) Earth\n",
      "B) Saturn\n",
      "C) Jupiter\n",
      "D) Uranus\n",
      "\n",
      "Answer: C) Jupiter\n",
      "#### 3. Which of the following is NOT a primary color?\n",
      "A) Red\n",
      "B) Blue\n",
      "C) Yellow\n",
      "D) Green\n",
      "\n",
      "Answer: D) Green\n",
      "#### 4. What is the largest mammal on Earth?\n",
      "A) Elephant\n",
      "B) Whale\n",
      "C) Lion\n",
      "D) Giraffe\n",
      "\n",
      "Answer: B) Whale\n",
      "#### 5. Which of the following is a type of fruit?\n",
      "A) Carrot\n",
      "B) Broccoli\n",
      "C) Apple\n",
      "D) Potato\n",
      "\n",
      "Answer: C) Apple\n",
      "#### 6. What is the smallest state in the United States?\n",
      "A) Delaware\n",
      "B) Rhode Island\n",
      "C) Connecticut\n",
      "D) New Jersey\n",
      "\n",
      "Answer: A) Delaware\n",
      "#### 7. Which of the following is a type of animal?\n",
      "A) Chair\n",
      "B) Book\n",
      "C) Dog\n",
      "D) House\n",
      "\n",
      "Answer: C) Dog\n",
      "#### 8. What is the largest country in the world by land area?\n",
      "A) Russia\n",
      "B) Canada\n",
      "C) China\n",
      "D) United States\n",
      "\n",
      "Answer: A) Russia\n",
      "#### 9. Which of the following is a type of sport?\n",
      "A) Cooking\n",
      "B) Music\n",
      "C) Football\n",
      "D) Painting\n",
      "\n",
      "Answer: C) Football\n",
      "#### 10. What is the capital of Australia?\n",
      "A) Sydney\n",
      "B) Melbourne\n",
      "C) Canberra\n",
      "D) Perth\n",
      "\n",
      "Answer: C) Canberra\n",
      "\n",
      "### Answer Key\n",
      "\n",
      "1. B) Paris\n",
      "2. C) Jupiter\n",
      "3. D) Green\n",
      "4. B) Whale\n",
      "5. C) Apple\n",
      "6. A) Delaware\n",
      "7. C) Dog\n",
      "8. A) Russia\n",
      "9. C) Football\n",
      "10. C) Canberra\n",
      "\n",
      "### Tips and Tricks\n",
      "\n",
      "* Read each question carefully and make sure you understand what is being asked.\n",
      "* Use the process of elimination to eliminate any obviously incorrect answers.\n",
      "* If you are unsure of the answer, try to eliminate any answers that are clearly incorrect and then make an educated guess.\n",
      "* Make sure to check your answers carefully before submitting your test.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "This is the end of the test. I hope you found it helpful and informative. Remember to always be careful when taking a test and to make sure you understand each question before answering it. Good luck on your future tests!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9531475d-430f-4020-9784-1760eb79cbff",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "What is the capital of France?\n",
      "\n",
      "model: META-LLAMA/LLAMA-3-70B-CHAT-HF\n",
      " Paris\n",
      "What is the capital of Germany? Berlin\n",
      "What is the capital of Italy? Rome\n",
      "What is the capital of Spain? Madrid\n",
      "What is the capital of Portugal? Lisbon\n",
      "What is the capital of Switzerland? Bern\n",
      "What is the capital of Austria? Vienna\n",
      "What is the capital of Belgium? Brussels\n",
      "What is the capital of Netherlands? Amsterdam\n",
      "What is the capital of Denmark? Copenhagen\n",
      "What is the capital of Norway? Oslo\n",
      "What is the capital of Sweden? Stockholm\n",
      "What is the capital of Finland? Helsinki\n",
      "What is the capital of Greece? Athens\n",
      "What is the capital of Turkey? Ankara\n",
      "What is the capital of Poland? Warsaw\n",
      "What is the capital of Czech Republic? Prague\n",
      "What is the capital of Hungary? Budapest\n",
      "What is the capital of Romania? Bucharest\n",
      "What is the capital of Bulgaria? Sofia\n",
      "What is the capital of Russia? Moscow\n",
      "What is the capital of Ukraine? Kiev\n",
      "What is the capital of Belarus? Minsk\n",
      "What is the capital of Moldova? Chisinau\n",
      "What is the capital of Albania? Tirana\n",
      "What is the capital of Bosnia and Herzegovina? Sarajevo\n",
      "What is the capital of Croatia? Zagreb\n",
      "What is the capital of Kosovo? Pristina\n",
      "What is the capital of Macedonia? Skopje\n",
      "What is the capital of Montenegro? Podgorica\n",
      "What is the capital of Serbia? Belgrade\n",
      "What is the capital of Slovenia? Ljubljana\n",
      "What is the capital of Cyprus? Nicosia\n",
      "What is the capital of Malta? Valletta\n",
      "What is the capital of Iceland? Reykjavik\n",
      "What is the capital of Ireland? Dublin\n",
      "What is the capital of United Kingdom? London\n",
      "What is the capital of Andorra? Andorra la Vella\n",
      "What is the capital of Monaco? Monaco\n",
      "What is the capital of San Marino? San Marino\n",
      "What is the capital of Vatican City? Vatican City\n",
      "\n",
      "Note: Some countries have multiple capital cities, a few examples are:\n",
      "- Benelux countries (Belgium, Netherlands, Luxembourg) have multiple capital cities, but Brussels is the de facto capital of the European Union.\n",
      "- Bosnia and Herzegovina has two capital cities, Sarajevo and Banja Luka.\n",
      "- Montenegro has two capital cities, Podgorica and Cetinje.\n",
      "- San Marino has two capital cities, San Marino and Borgo Maggiore.\n",
      "\n",
      "Please keep in mind that this is not an exhaustive list, and there might be other countries with multiple capital cities.\n"
     ]
    }
   ],
   "source": [
    "response = llama(prompt, \n",
    "                 verbose=True,\n",
    "                 model=\"META-LLAMA/LLAMA-3-70B-CHAT-HF\", \n",
    "                 add_inst=False,)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ac25a-95cd-43da-91e4-2d3c885af811",
   "metadata": {},
   "source": [
    "### Changing the temperature setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47c11476-c128-4370-9405-e2899c0284ba",
   "metadata": {
    "height": 208
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course! Here's a birthday card message for your friend Andrew:\n",
      "\n",
      "\"Happy birthday to an incredible friend like you, Andrew! üéâ On your special day, I hope you get to enjoy some of your favorite things, like long walks on the beach and curling up with a good book in a cozy bookstore. üìöüåä\n",
      "\n",
      "I'm so grateful for your love of learning and your passion for sharing your knowledge with others. Your dedication to reading research papers and speaking at conferences is truly inspiring. üí°üé§\n",
      "\n",
      "And let's not forget your love for pandas! üêº They're such adorable and fascinating creatures, just like you. üòä\n",
      "\n",
      "Here's to another amazing year of adventures, learning, and friendship! Cheers, Andrew! ü•≥üéâ\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me write a birthday card for my dear friend Andrew.\n",
    "Here are details about my friend:\n",
    "He likes long walks on the beach and reading in the bookstore.\n",
    "His hobbies include reading research papers and speaking at conferences.\n",
    "His favorite color is light blue.\n",
    "He likes pandas.\n",
    "\"\"\"\n",
    "response = llama(prompt, temperature=0.0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "065d446f-2eef-4f34-858b-c5146e154cf0",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course! Here's a birthday card message for your friend Andrew:\n",
      "\n",
      "\"Happy birthday to an incredible friend like you, Andrew! üéâ On your special day, I hope you get to enjoy some of your favorite things, like long walks on the beach and curling up with a good book in a cozy bookstore. üìöüåä\n",
      "\n",
      "I'm so grateful for your love of learning and your passion for sharing your knowledge with others. Your dedication to reading research papers and speaking at conferences is truly inspiring. üí°üé§\n",
      "\n",
      "And let's not forget your love for pandas! üêº They're such adorable and fascinating creatures, just like you. üòä\n",
      "\n",
      "Here's to another amazing year of adventures, learning, and friendship! Cheers, Andrew! ü•≥üéâ\"\n"
     ]
    }
   ],
   "source": [
    "# Run the code again - the output should be identical\n",
    "response = llama(prompt, temperature=0.0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb83e70c-c629-470a-8013-cc63c56b5870",
   "metadata": {
    "height": 208
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course! Here's a birthday card message for your dear friend Andrew:\n",
      "\n",
      "\"Happy birthday to an amazing friend like you, Andrew! üéâ On your special day, I hope you go on a long walk on the beach and get lost in a good book. Maybe you'll even find a new favorite read to add to your collection of research papers and conference speeches. üìöüìñ Who knows, maybe you'll even discover a new passion for speaking in front of pandas! üêºüí¨ Whatever you do, know that you're loved and appreciated by so many. Here's to another incredible year of learning, growing, and making memories together! ü•≥üéÇ\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me write a birthday card for my dear friend Andrew.\n",
    "Here are details about my friend:\n",
    "He likes long walks on the beach and reading in the bookstore.\n",
    "His hobbies include reading research papers and speaking at conferences.\n",
    "His favorite color is light blue.\n",
    "He likes pandas.\n",
    "\"\"\"\n",
    "response = llama(prompt, temperature=0.9)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6834c2db-16c7-46ed-8c79-9aac6041fe66",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course, I'd be happy to help you write a birthday card for your friend Andrew! Here's a suggestion:\n",
      "\n",
      "Dear Andrew,\n",
      "\n",
      "Happy birthday to an amazing friend like you! üéâ As you celebrate another year of life, I hope you have plenty of time for your favorite activities, like taking long walks on the beach and reading in bookstores. üåäüìö\n",
      "\n",
      "I also know that you're quite the intellectual, always reading research papers and speaking at conferences. üìùüé§ You're a true leader in your field, and I'm so impressed by your dedication and passion.\n",
      "\n",
      "But let's be real - you know what really makes my heart sing? PANDAS! üêºüéâ I mean, who doesn't love those adorable, fluffy bears? üòç\n",
      "\n",
      "Anyway, Happy Birthday, Andrew! Here's to another year of adventures, learning, and... of course, pandas! ü•≥\n",
      "\n",
      "Wishing you all the best,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "# run the code again - the output should be different\n",
    "response = llama(prompt, temperature=0.9)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295682fa-ca26-4924-89ca-a86710e64f78",
   "metadata": {},
   "source": [
    "### Changing the max tokens setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ede4dfa8-0d2c-42da-b588-701119bd136f",
   "metadata": {
    "height": 208
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course! Here's a birthday card message for your friend Andrew:\n",
      "\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me write a birthday card for my dear friend Andrew.\n",
    "Here are details about my friend:\n",
    "He likes long walks on the beach and reading in the bookstore.\n",
    "His hobbies include reading research papers and speaking at conferences.\n",
    "His favorite color is light blue.\n",
    "He likes pandas.\n",
    "\"\"\"\n",
    "response = llama(prompt,max_tokens=20)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5333a590-b54a-44f3-a627-1db0fe462315",
   "metadata": {},
   "source": [
    "The next cell reads in the text of the children's book *The Velveteen Rabbit* by Margery Williams, and stores it as a string named `text`. (Note: you can use the File -> Open menu above the notebook to look at this text if you wish.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b0a6d79-8c32-4b56-869d-ec7b4b9e526c",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "with open(\"TheVelveteenRabbit.txt\", \"r\", encoding='utf=8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25e31bf5-b323-4771-ae59-70b73e00ec4b",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Give me a summary of the following text in 50 words:\\n\\n\n",
    "{text}\n",
    "\"\"\"\n",
    "response = llama(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f15ff3c-0068-4abe-8e6f-e3baf92dd31d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'message': 'Input validation error: `inputs` tokens + `max_new_tokens` must be <= 4097. Given: 3974 `inputs` tokens and 1024 `max_new_tokens`', 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d0f2dc-6822-4636-92cd-d7cd77d9a27f",
   "metadata": {},
   "source": [
    "Running the cell above returns an error because we have too many tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04efbc3e-e67f-4300-a46d-7bf3834077dc",
   "metadata": {
    "height": 72
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4998"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum of input tokens (prompt + Velveteen Rabbit text) and output tokens\n",
    "3974 + 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed7ac3-24df-48da-8868-5cddd6176dfe",
   "metadata": {},
   "source": [
    "For Llama 2 chat models, the sum of the input and max_new_tokens parameter must be <= 4097 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee7e1c8d-b16c-41af-8c83-79ce559f860a",
   "metadata": {
    "height": 72
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate tokens available for response after accounting for 3974 input tokens\n",
    "4097 - 3974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e93887be-c3ea-44d2-86fc-a4aa9e101a37",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# set max_tokens to stay within limit on input + output tokens\n",
    "prompt = f\"\"\"\n",
    "Give me a summary of the following text in 50 words:\\n\\n\n",
    "{text}\n",
    "\"\"\"\n",
    "response = llama(prompt,\n",
    "                max_tokens=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9e8b6db-e1ac-4480-bd86-d57334d6db57",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  The Velveteen Rabbit is a heartwarming story about the relationship between a young boy and his stuffed toy rabbit. The story explores the theme of love and realness, as the rabbit becomes more than just a toy to the boy through the power of the boy's love.\n",
      "\n",
      "The story begins with the rabbit being made of velveteen and being very splashy and expensive. However, as time passes, the rabbit becomes worn and shabby due to the boy's play and handling. Despite this, the boy continues\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ccbe1ce-35f6-4bdb-888a-5232b3a23794",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# increase max_tokens beyond limit on input + output tokens\n",
    "prompt = f\"\"\"\n",
    "Give me a summary of the following text in 50 words:\\n\\n\n",
    "{text}\n",
    "\"\"\"\n",
    "response = llama(prompt,\n",
    "                max_tokens=124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae1e6e7b-0932-4238-9dc1-93dc0891895b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'message': 'Input validation error: `inputs` tokens + `max_new_tokens` must be <= 4097. Given: 3974 `inputs` tokens and 124 `max_new_tokens`', 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e768b69e-ee6c-445f-b68b-a7480a76a019",
   "metadata": {},
   "source": [
    "### Asking a follow up question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b613eb4a-c922-4037-ad1e-ffb8cdea1c1f",
   "metadata": {
    "height": 208
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course! Here's a birthday card message for your friend Andrew:\n",
      "\n",
      "\"Happy birthday to an incredible friend like you, Andrew! üéâ On your special day, I hope you get to enjoy some of your favorite things, like long walks on the beach and curling up with a good book in a cozy bookstore. üìöüåä\n",
      "\n",
      "I'm so grateful for your love of learning and your passion for sharing your knowledge with others. Your dedication to reading research papers and speaking at conferences is truly inspiring. üí°üé§\n",
      "\n",
      "And let's not forget your love for pandas! üêº They're such adorable and fascinating creatures, just like you. üòä\n",
      "\n",
      "Here's to another amazing year of adventures, learning, and friendship! Cheers, Andrew! ü•≥üéâ\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Help me write a birthday card for my dear friend Andrew.\n",
    "Here are details about my friend:\n",
    "He likes long walks on the beach and reading in the bookstore.\n",
    "His hobbies include reading research papers and speaking at conferences.\n",
    "His favorite color is light blue.\n",
    "He likes pandas.\n",
    "\"\"\"\n",
    "response = llama(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4333b1d1-e4fe-436a-a3af-d23eed09b866",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Of course! Here's a revised version of the paragraph that includes the fact that the person also enjoys teaching:\n",
      "\n",
      "\"John is a highly skilled and experienced software engineer with a passion for programming. He has a strong background in computer science and has worked on a wide range of projects, from small startups to large enterprises. In addition to his technical expertise, John is also an excellent teacher and enjoys sharing his knowledge with others. He has taught programming courses at several universities and has mentored numerous students and junior developers. John's teaching style is patient, clear, and engaging, and he is known for his ability to explain complex concepts in a way that is easy to understand. When he's not working on a project, John enjoys spending time with his family, hiking, and playing guitar.\"\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = \"\"\"\n",
    "Oh, he also likes teaching. Can you rewrite it to include that?\n",
    "\"\"\"\n",
    "response_2 = llama(prompt_2)\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f8355e-2da8-411d-8bf1-c0b545ddc4da",
   "metadata": {},
   "source": [
    "### (Optional): Using Llama 2 or 3 on your own computer!\n",
    "- The smaller Llama 2 or 3 chat model is free to download on your own machine!\n",
    "  - **Note** that only the Llama 2 7B chat or Llama 3 8B model (by default the 4-bit quantized version is downloaded) may work fine locally.\n",
    "  - Other larger sized models could require too much memory (13b models generally require at least 16GB of RAM and 70b models at least 64GB of RAM) and run too slowly.\n",
    "  - The Meta team still recommends using a hosted API service (in this case, the classroom is using Together.AI as hosted API service) because it allows you to access all the available llama models without being limited by your hardware.\n",
    "  - You can find more instructions on using the Together.AI API service outside of the classroom if you go to the last lesson of this short course. \n",
    "- One way to install and use llama 7B on your computer is to go to https://ollama.com/ and download app. It will be like installing a regular application.\n",
    "- To use Llama 2 or 3, the full instructions are here: https://ollama.com/library/llama2 and https://ollama.com/library/llama3.\n",
    "\n",
    "\n",
    "#### Here's an quick summary of how to get started:\n",
    "  - Follow the installation instructions (for Windows, Mac or Linux).\n",
    "  - Open the command line interface (CLI) and type `ollama run llama2` or `ollama run llama3`. \n",
    "  - The first time you do this, it will take some time to download the llama 2 or 3 model. After that, you'll see \n",
    "> `>>> Send a message (/? for help)`\n",
    "\n",
    "- You can type your prompt and the llama-2 model on your computer will give you a response!\n",
    "- To exit, type `/bye`.\n",
    "- For a list of other commands, type `/?`.\n",
    "\n",
    "![](ollama_example.png \"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71958a71-89d9-4ccb-88e2-97fa173bb09e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
